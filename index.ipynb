{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extensions to Linear Models - Lab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "In this lab, you'll practice many concepts learned in this section, from adding interactions and polynomials to your model to AIC and BIC!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "You will be able to:\n",
    "- Build a linear regression model with polynomial features/interactions\n",
    "- Perform regularization\n",
    "- Use AIC and BIC to select the best value for the regularization parameter\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's get started!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import all the necessary packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from sklearn.datasets import load_boston"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Look at a Baseline Boston Housing Data Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the Boston housing data set, use all the predictors in their scaled version (using `preprocessing.scale`. Look at a baseline model using *scaled variables* as predictors. Use 5-fold cross-validation this time and use the $R^2$ score to evaluate the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "regression = LinearRegression()\n",
    "boston = load_boston()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = pd.DataFrame(boston.target, columns=['target'])\n",
    "df = pd.DataFrame(boston.data, columns=boston.feature_names)\n",
    "\n",
    "X_scaled = preprocessing.scale(df)\n",
    "X_scaled = pd.DataFrame(X_scaled, columns=boston.feature_names)\n",
    "\n",
    "all_df = pd.concat([y,X_scaled], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7176324491383005"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "baseline = np.mean(cross_val_score(regression, X_scaled, y, scoring='r2', cv=cv))\n",
    "baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Include interactions\n",
    "\n",
    "Look at all the possible combinations of variables for interactions by adding interactions one by one to the baseline model. Next, evaluate that model using 5-fold classification and store the $R^2$ to compare it with the baseline model.\n",
    "\n",
    "You've created code for this before in the interactions lab, yet this time, you have scaled the variables so the outcomes may look different. \n",
    "\n",
    "Print the 7 most important interactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.7832165803604273, ('RM', 'LSTAT')), (0.7752514777398676, ('RM', 'TAX')), (0.7700767546577312, ('RM', 'RAD')), (0.7635456330512322, ('RM', 'PTRATIO')), (0.7566187103630421, ('INDUS', 'RM')), (0.7461351850787393, ('NOX', 'RM')), (0.7421152576041224, ('RM', 'AGE'))]\n"
     ]
    }
   ],
   "source": [
    "# Your code here\n",
    "from itertools import combinations\n",
    "\n",
    "combos = list(combinations(boston.feature_names, 2))\n",
    "X_copy = X_scaled.copy()\n",
    "\n",
    "scores = []\n",
    "\n",
    "for c in combos:\n",
    "    X_copy['interactions'] = X_copy[c[0]] * X_copy[c[1]]\n",
    "    cv = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "    score = np.mean(cross_val_score(regression, X_copy, y, scoring='r2', cv=cv))\n",
    "    if score > baseline:\n",
    "        scores.append((score,c))\n",
    "        \n",
    "print(sorted(scores, reverse=True)[:7])   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write code to include the 7 most important interactions in your data set by adding 7 columns. Name the columns \"var1_var2\" with var1 and var2 the two variables in the interaction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>RM_LSTAT</th>\n",
       "      <th>RM_TAX</th>\n",
       "      <th>RM_RAD</th>\n",
       "      <th>RM_PTRATIO</th>\n",
       "      <th>INDUS_RM</th>\n",
       "      <th>NOX_RM</th>\n",
       "      <th>RM_AGE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.417713</td>\n",
       "      <td>0.284830</td>\n",
       "      <td>-1.287909</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>-0.144217</td>\n",
       "      <td>0.413672</td>\n",
       "      <td>-0.120013</td>\n",
       "      <td>0.140214</td>\n",
       "      <td>-0.982843</td>\n",
       "      <td>-0.666608</td>\n",
       "      <td>-1.459000</td>\n",
       "      <td>0.441052</td>\n",
       "      <td>-1.075562</td>\n",
       "      <td>-0.444930</td>\n",
       "      <td>-0.275757</td>\n",
       "      <td>-0.406574</td>\n",
       "      <td>-0.603547</td>\n",
       "      <td>-0.532772</td>\n",
       "      <td>-0.059659</td>\n",
       "      <td>-0.049646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.415269</td>\n",
       "      <td>-0.487722</td>\n",
       "      <td>-0.593381</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>-0.740262</td>\n",
       "      <td>0.194274</td>\n",
       "      <td>0.367166</td>\n",
       "      <td>0.557160</td>\n",
       "      <td>-0.867883</td>\n",
       "      <td>-0.987329</td>\n",
       "      <td>-0.303094</td>\n",
       "      <td>0.441052</td>\n",
       "      <td>-0.492439</td>\n",
       "      <td>-0.095668</td>\n",
       "      <td>-0.191813</td>\n",
       "      <td>-0.168607</td>\n",
       "      <td>-0.058883</td>\n",
       "      <td>-0.115279</td>\n",
       "      <td>-0.143814</td>\n",
       "      <td>0.071331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.415272</td>\n",
       "      <td>-0.487722</td>\n",
       "      <td>-0.593381</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>-0.740262</td>\n",
       "      <td>1.282714</td>\n",
       "      <td>-0.265812</td>\n",
       "      <td>0.557160</td>\n",
       "      <td>-0.867883</td>\n",
       "      <td>-0.987329</td>\n",
       "      <td>-0.303094</td>\n",
       "      <td>0.396427</td>\n",
       "      <td>-1.208727</td>\n",
       "      <td>-1.550451</td>\n",
       "      <td>-1.266461</td>\n",
       "      <td>-1.113245</td>\n",
       "      <td>-0.388783</td>\n",
       "      <td>-0.761138</td>\n",
       "      <td>-0.949544</td>\n",
       "      <td>-0.340960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.414680</td>\n",
       "      <td>-0.487722</td>\n",
       "      <td>-1.306878</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>-0.835284</td>\n",
       "      <td>1.016303</td>\n",
       "      <td>-0.809889</td>\n",
       "      <td>1.077737</td>\n",
       "      <td>-0.752922</td>\n",
       "      <td>-1.106115</td>\n",
       "      <td>0.113032</td>\n",
       "      <td>0.416163</td>\n",
       "      <td>-1.361517</td>\n",
       "      <td>-1.383713</td>\n",
       "      <td>-1.124148</td>\n",
       "      <td>-0.765197</td>\n",
       "      <td>0.114875</td>\n",
       "      <td>-1.328183</td>\n",
       "      <td>-0.848901</td>\n",
       "      <td>-0.823092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.410409</td>\n",
       "      <td>-0.487722</td>\n",
       "      <td>-1.306878</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>-0.835284</td>\n",
       "      <td>1.228577</td>\n",
       "      <td>-0.511180</td>\n",
       "      <td>1.077737</td>\n",
       "      <td>-0.752922</td>\n",
       "      <td>-1.106115</td>\n",
       "      <td>0.113032</td>\n",
       "      <td>0.441052</td>\n",
       "      <td>-1.026501</td>\n",
       "      <td>-1.261136</td>\n",
       "      <td>-1.358947</td>\n",
       "      <td>-0.925023</td>\n",
       "      <td>0.138869</td>\n",
       "      <td>-1.605599</td>\n",
       "      <td>-1.026210</td>\n",
       "      <td>-0.628023</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       CRIM        ZN     INDUS      CHAS       NOX        RM       AGE  \\\n",
       "0 -0.417713  0.284830 -1.287909 -0.272599 -0.144217  0.413672 -0.120013   \n",
       "1 -0.415269 -0.487722 -0.593381 -0.272599 -0.740262  0.194274  0.367166   \n",
       "2 -0.415272 -0.487722 -0.593381 -0.272599 -0.740262  1.282714 -0.265812   \n",
       "3 -0.414680 -0.487722 -1.306878 -0.272599 -0.835284  1.016303 -0.809889   \n",
       "4 -0.410409 -0.487722 -1.306878 -0.272599 -0.835284  1.228577 -0.511180   \n",
       "\n",
       "        DIS       RAD       TAX   PTRATIO         B     LSTAT  RM_LSTAT  \\\n",
       "0  0.140214 -0.982843 -0.666608 -1.459000  0.441052 -1.075562 -0.444930   \n",
       "1  0.557160 -0.867883 -0.987329 -0.303094  0.441052 -0.492439 -0.095668   \n",
       "2  0.557160 -0.867883 -0.987329 -0.303094  0.396427 -1.208727 -1.550451   \n",
       "3  1.077737 -0.752922 -1.106115  0.113032  0.416163 -1.361517 -1.383713   \n",
       "4  1.077737 -0.752922 -1.106115  0.113032  0.441052 -1.026501 -1.261136   \n",
       "\n",
       "     RM_TAX    RM_RAD  RM_PTRATIO  INDUS_RM    NOX_RM    RM_AGE  \n",
       "0 -0.275757 -0.406574   -0.603547 -0.532772 -0.059659 -0.049646  \n",
       "1 -0.191813 -0.168607   -0.058883 -0.115279 -0.143814  0.071331  \n",
       "2 -1.266461 -1.113245   -0.388783 -0.761138 -0.949544 -0.340960  \n",
       "3 -1.124148 -0.765197    0.114875 -1.328183 -0.848901 -0.823092  \n",
       "4 -1.358947 -0.925023    0.138869 -1.605599 -1.026210 -0.628023  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code here\n",
    "top_7 = sorted(scores, reverse=True)[:7]\n",
    "df_inter = X_scaled.copy()\n",
    "for s,c in top_7:\n",
    "    df_inter[c[0]+'_'+c[1]] = df_inter[c[0]] * df_inter[c[1]]\n",
    "    \n",
    "df_inter.head()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Include Polynomials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try polynomials of 2, 3 and 4 for each variable, in a similar way you did for interactions (by looking at your baseline model and seeing how $R^2$ increases). Do understand that when going for a polynomial of 4, the particular column is raised to the power of 2 and 3 as well in other terms. We only want to include \"pure\" polynomials, so make sure no interactions are included. We want the result to return a list that contain tuples of the form:\n",
    "\n",
    "`(var_name, degree, R2)`, so eg. `('DIS', 3, 0.732)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# always generate polynomiaFeatures BEFORE scaling\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "polynomials = []\n",
    "for col in df.columns:\n",
    "    for degree in [2,3,4]:\n",
    "        x_copy = X_scaled.copy()\n",
    "        poly = PolynomialFeatures(degree, include_bias=False)\n",
    "        X = poly.fit_transform(df[[col]])\n",
    "        x_copy = pd.concat([x_copy.drop(col,axis=1),pd.DataFrame(X)], axis=1)\n",
    "        score = np.mean(cross_val_score(regression, x_copy, y, scoring='r2', cv=cv))\n",
    "        if score > baseline:\n",
    "            polynomials.append((col, degree, score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each variable, print out the maximum R2 possible when including Polynomials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        1\n",
       "ZN       2    0.720420\n",
       "         3    0.723175\n",
       "         4    0.719769\n",
       "INDUS    2    0.722992\n",
       "         3    0.723253\n",
       "         4    0.723221\n",
       "CHAS     4    0.717632\n",
       "NOX      2    0.718076\n",
       "         3    0.718304\n",
       "         4    0.720555\n",
       "RM       2    0.782271\n",
       "         3    0.780715\n",
       "         4    0.800385\n",
       "AGE      2    0.720900\n",
       "         3    0.722149\n",
       "         4    0.722107\n",
       "DIS      2    0.731965\n",
       "         3    0.736625\n",
       "         4    0.730780\n",
       "RAD      4    0.719489\n",
       "TAX      2    0.718751\n",
       "         3    0.720932\n",
       "         4    0.723968\n",
       "PTRATIO  2    0.720892\n",
       "         3    0.719284\n",
       "B        2    0.719702\n",
       "         3    0.719442\n",
       "         4    0.717854\n",
       "LSTAT    2    0.771852\n",
       "         3    0.774011\n",
       "         4    0.781889\n",
       "Name: 2, dtype: float64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code here\n",
    "polys = pd.DataFrame(polynomials)\n",
    "polys.groupby([0,1], sort=False)[2].max()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which two variables seem to benefit most from adding Polynomial terms?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add Polynomials for the two features that seem to benefit the most, as in have the best R squared compared to the baseline model. For each of the two feature, raise to the Polynomial that generates the best result. Make sure to start from the data set `df_inter` so the final data set has both interactions and polynomials in the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "for col in [\"RM\", \"LSTAT\"]:\n",
    "    poly = PolynomialFeatures(4, include_bias=False)\n",
    "    X = poly.fit_transform(df[[col]])\n",
    "    colnames= poly.get_feature_names(col)\n",
    "    df_inter = pd.concat([df_inter.drop(col, axis=1),pd.DataFrame(X, columns=colnames)], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "check out your final data set and make sure that your interaction terms as well as your polynomial terms are included."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>...</th>\n",
       "      <th>NOX_RM</th>\n",
       "      <th>RM_AGE</th>\n",
       "      <th>R</th>\n",
       "      <th>R^2</th>\n",
       "      <th>R^3</th>\n",
       "      <th>R^4</th>\n",
       "      <th>L</th>\n",
       "      <th>L^2</th>\n",
       "      <th>L^3</th>\n",
       "      <th>L^4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.417713</td>\n",
       "      <td>0.284830</td>\n",
       "      <td>-1.287909</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>-0.144217</td>\n",
       "      <td>-0.120013</td>\n",
       "      <td>0.140214</td>\n",
       "      <td>-0.982843</td>\n",
       "      <td>-0.666608</td>\n",
       "      <td>-1.459000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.059659</td>\n",
       "      <td>-0.049646</td>\n",
       "      <td>6.575</td>\n",
       "      <td>43.230625</td>\n",
       "      <td>284.241359</td>\n",
       "      <td>1868.886938</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.8004</td>\n",
       "      <td>123.505992</td>\n",
       "      <td>615.059840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.415269</td>\n",
       "      <td>-0.487722</td>\n",
       "      <td>-0.593381</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>-0.740262</td>\n",
       "      <td>0.367166</td>\n",
       "      <td>0.557160</td>\n",
       "      <td>-0.867883</td>\n",
       "      <td>-0.987329</td>\n",
       "      <td>-0.303094</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.143814</td>\n",
       "      <td>0.071331</td>\n",
       "      <td>6.421</td>\n",
       "      <td>41.229241</td>\n",
       "      <td>264.732956</td>\n",
       "      <td>1699.850313</td>\n",
       "      <td>9.14</td>\n",
       "      <td>83.5396</td>\n",
       "      <td>763.551944</td>\n",
       "      <td>6978.864768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.415272</td>\n",
       "      <td>-0.487722</td>\n",
       "      <td>-0.593381</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>-0.740262</td>\n",
       "      <td>-0.265812</td>\n",
       "      <td>0.557160</td>\n",
       "      <td>-0.867883</td>\n",
       "      <td>-0.987329</td>\n",
       "      <td>-0.303094</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.949544</td>\n",
       "      <td>-0.340960</td>\n",
       "      <td>7.185</td>\n",
       "      <td>51.624225</td>\n",
       "      <td>370.920057</td>\n",
       "      <td>2665.060607</td>\n",
       "      <td>4.03</td>\n",
       "      <td>16.2409</td>\n",
       "      <td>65.450827</td>\n",
       "      <td>263.766833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.414680</td>\n",
       "      <td>-0.487722</td>\n",
       "      <td>-1.306878</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>-0.835284</td>\n",
       "      <td>-0.809889</td>\n",
       "      <td>1.077737</td>\n",
       "      <td>-0.752922</td>\n",
       "      <td>-1.106115</td>\n",
       "      <td>0.113032</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.848901</td>\n",
       "      <td>-0.823092</td>\n",
       "      <td>6.998</td>\n",
       "      <td>48.972004</td>\n",
       "      <td>342.706084</td>\n",
       "      <td>2398.257176</td>\n",
       "      <td>2.94</td>\n",
       "      <td>8.6436</td>\n",
       "      <td>25.412184</td>\n",
       "      <td>74.711821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.410409</td>\n",
       "      <td>-0.487722</td>\n",
       "      <td>-1.306878</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>-0.835284</td>\n",
       "      <td>-0.511180</td>\n",
       "      <td>1.077737</td>\n",
       "      <td>-0.752922</td>\n",
       "      <td>-1.106115</td>\n",
       "      <td>0.113032</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.026210</td>\n",
       "      <td>-0.628023</td>\n",
       "      <td>7.147</td>\n",
       "      <td>51.079609</td>\n",
       "      <td>365.065966</td>\n",
       "      <td>2609.126456</td>\n",
       "      <td>5.33</td>\n",
       "      <td>28.4089</td>\n",
       "      <td>151.419437</td>\n",
       "      <td>807.065599</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       CRIM        ZN     INDUS      CHAS       NOX       AGE       DIS  \\\n",
       "0 -0.417713  0.284830 -1.287909 -0.272599 -0.144217 -0.120013  0.140214   \n",
       "1 -0.415269 -0.487722 -0.593381 -0.272599 -0.740262  0.367166  0.557160   \n",
       "2 -0.415272 -0.487722 -0.593381 -0.272599 -0.740262 -0.265812  0.557160   \n",
       "3 -0.414680 -0.487722 -1.306878 -0.272599 -0.835284 -0.809889  1.077737   \n",
       "4 -0.410409 -0.487722 -1.306878 -0.272599 -0.835284 -0.511180  1.077737   \n",
       "\n",
       "        RAD       TAX   PTRATIO     ...         NOX_RM    RM_AGE      R  \\\n",
       "0 -0.982843 -0.666608 -1.459000     ...      -0.059659 -0.049646  6.575   \n",
       "1 -0.867883 -0.987329 -0.303094     ...      -0.143814  0.071331  6.421   \n",
       "2 -0.867883 -0.987329 -0.303094     ...      -0.949544 -0.340960  7.185   \n",
       "3 -0.752922 -1.106115  0.113032     ...      -0.848901 -0.823092  6.998   \n",
       "4 -0.752922 -1.106115  0.113032     ...      -1.026210 -0.628023  7.147   \n",
       "\n",
       "         R^2         R^3          R^4     L      L^2         L^3          L^4  \n",
       "0  43.230625  284.241359  1868.886938  4.98  24.8004  123.505992   615.059840  \n",
       "1  41.229241  264.732956  1699.850313  9.14  83.5396  763.551944  6978.864768  \n",
       "2  51.624225  370.920057  2665.060607  4.03  16.2409   65.450827   263.766833  \n",
       "3  48.972004  342.706084  2398.257176  2.94   8.6436   25.412184    74.711821  \n",
       "4  51.079609  365.065966  2609.126456  5.33  28.4089  151.419437   807.065599  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code here\n",
    "df_inter.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full model R-squared"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check out the R-squared of the full model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8061116489236977"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code here\n",
    "np.mean(cross_val_score(regression, df_inter, y, scoring='r2', cv=cv))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding the best Lasso regularization parameter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You've learned that, when using Lasso regularization, your coefficients shrink to 0 when using a higher regularization parameter. Now the question is which value we should choose for the regularization parameter. \n",
    "\n",
    "This is where the AIC and BIC come in handy! We'll use both criteria in what follows and perform cross-validation to select an optimal value of the regularization parameter alpha of the Lasso estimator.\n",
    "\n",
    "Read the page here: https://scikit-learn.org/stable/auto_examples/linear_model/plot_lasso_model_selection.html and create a similar plot as the first one listed on the page. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import LassoCV, LassoLarsCV, LassoLarsIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a1a48d630>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Your code here\n",
    "model_bic = LassoLarsIC(criterion='bic')\n",
    "model_bic.fit(df_inter, y)\n",
    "alpha_bic_ = model_bic.alpha_\n",
    "\n",
    "model_aic = LassoLarsIC(criterion='aic')\n",
    "model_aic.fit(df_inter, y)\n",
    "alpha_aic_ = model_aic.alpha_\n",
    "\n",
    "\n",
    "def plot_ic_criterion(model, name, color):\n",
    "    alpha_ = model.alpha_\n",
    "    alphas_ = model.alphas_\n",
    "    criterion_ = model.criterion_\n",
    "    plt.plot(-np.log10(alphas_), criterion_, '--', color=color,\n",
    "             linewidth=3, label='%s criterion' % name)\n",
    "    plt.axvline(-np.log10(alpha_), color=color, linewidth=3,\n",
    "                label='alpha: %s estimate' % name)\n",
    "    plt.xlabel('-log(alpha)')\n",
    "    plt.ylabel('criterion')\n",
    "\n",
    "plt.figure()\n",
    "plot_ic_criterion(model_aic, 'AIC', 'b')\n",
    "plot_ic_criterion(model_bic, 'BIC', 'r')\n",
    "plt.legend()\n",
    "plt.title('Information-criterion for model selection');\n",
    "          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze the final result\n",
    "\n",
    "Finally, use the best value for regularization parameter according to AIC and BIC and compare the R squared parameters and MSE using train-test-split. Compare with the baseline model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training r^2: 0.7163087807237563\n",
      "Testing r^2: 0.7771537365132459\n",
      "Training MSE: 21.998585000685544\n",
      "Testing MSE: 23.023231077164624\n"
     ]
    }
   ],
   "source": [
    "# Code for baseline model\n",
    "from sklearn.metrics import mean_squared_error, mean_squared_log_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y)\n",
    "\n",
    "linreg_all = LinearRegression()\n",
    "linreg_all.fit(X_train, y_train)\n",
    "print('Training r^2:', linreg_all.score(X_train, y_train))\n",
    "print('Testing r^2:', linreg_all.score(X_test, y_test))\n",
    "print('Training MSE:', mean_squared_error(y_train, linreg_all.predict(X_train)))\n",
    "print('Testing MSE:', mean_squared_error(y_test, linreg_all.predict(X_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training r^2: 0.831156750749461\n",
      "Testing r^2: 0.8284615392150575\n",
      "Training MSE: 14.26163366280747\n",
      "Testing MSE: 14.438317477365572\n"
     ]
    }
   ],
   "source": [
    "# code for lasso with alpha from AIC\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_inter, y)\n",
    "\n",
    "lasso = Lasso(alpha= alpha_aic_) \n",
    "lasso.fit(X_train, y_train)\n",
    "print('Training r^2:', lasso.score(X_train, y_train))\n",
    "print('Testing r^2:', lasso.score(X_test, y_test))\n",
    "print('Training MSE:', mean_squared_error(y_train, lasso.predict(X_train)))\n",
    "print('Testing MSE:', mean_squared_error(y_test, lasso.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training r^2: 0.8302772334124529\n",
      "Testing r^2: 0.8306152275667797\n",
      "Training MSE: 14.33592359809464\n",
      "Testing MSE: 14.257042467509578\n"
     ]
    }
   ],
   "source": [
    "# code for lasso with alpha from BIC\n",
    "\n",
    "lasso = Lasso(alpha= alpha_bic_) \n",
    "lasso.fit(X_train, y_train)\n",
    "print('Training r^2:', lasso.score(X_train, y_train))\n",
    "print('Testing r^2:', lasso.score(X_test, y_test))\n",
    "print('Training MSE:', mean_squared_error(y_train, lasso.predict(X_train)))\n",
    "print('Testing MSE:', mean_squared_error(y_test, lasso.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Level Up - Optional"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a Lasso Path\n",
    "\n",
    "From this section, you know that when using lasso, more parameters shrink to zero as your regularization parameter goes up. In Scikit-Learn there is a function lasso_path which visualizes the shrinkage of the coefficients while alpha changes. Try this out yourself!\n",
    "\n",
    "https://scikit-learn.org/stable/auto_examples/linear_model/plot_lasso_coordinate_descent_path.html#sphx-glr-auto-examples-linear-model-plot-lasso-coordinate-descent-path-py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AIC and BIC for subset selection\n",
    "This notebook shows how you can use AIC and BIC purely for feature selection. Try this code out on our Boston Housing data!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://xavierbourretsicotte.github.io/subset_selection.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations! You now know how to create better linear models and how to use AIC and BIC for both feature selection and to optimize your regularization parameter when performing Ridge and Lasso. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
